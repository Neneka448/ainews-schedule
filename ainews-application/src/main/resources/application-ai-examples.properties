# Spring AI Configuration Examples
# This file contains example configurations for various OpenAI-compatible services
# Copy the relevant section to your application.properties or application-{profile}.properties

# =============================================================================
# OFFICIAL OPENAI CONFIGURATION
# =============================================================================

# Standard OpenAI Configuration
spring.ai.openai.base-url=https://api.openai.com/v1
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.chat.options.model=gpt-4o-mini
spring.ai.openai.chat.options.temperature=0.8
spring.ai.openai.chat.options.max-tokens=2048

# OpenAI with Organization and Project
#spring.ai.openai.organization-id=org-your-organization-id
#spring.ai.openai.project-id=proj_your-project-id

# =============================================================================
# AZURE OPENAI SERVICE CONFIGURATION
# =============================================================================

# Azure OpenAI Service
#spring.ai.openai.base-url=https://your-resource-name.openai.azure.com/openai/deployments/your-deployment-name
#spring.ai.openai.api-key=${AZURE_OPENAI_API_KEY}
#spring.ai.openai.chat.options.model=gpt-4
#spring.ai.openai.chat.options.temperature=0.7

# =============================================================================
# LOCAL AI SERVICES CONFIGURATION
# =============================================================================

# Ollama Local Service
#spring.ai.openai.base-url=http://localhost:11434/v1
#spring.ai.openai.api-key=not-needed
#spring.ai.openai.chat.options.model=llama2
#spring.ai.openai.chat.options.temperature=0.8

# LocalAI Service
#spring.ai.openai.base-url=http://localhost:8080/v1
#spring.ai.openai.api-key=not-needed
#spring.ai.openai.chat.options.model=gpt-3.5-turbo
#spring.ai.openai.chat.options.temperature=0.7

# =============================================================================
# THIRD-PARTY OPENAI-COMPATIBLE SERVICES
# =============================================================================

# Groq (Fast Inference)
#spring.ai.openai.base-url=https://api.groq.com/openai/v1
#spring.ai.openai.api-key=${GROQ_API_KEY}
#spring.ai.openai.chat.options.model=mixtral-8x7b-32768
#spring.ai.openai.chat.options.temperature=0.7

# Perplexity AI
#spring.ai.openai.base-url=https://api.perplexity.ai
#spring.ai.openai.api-key=${PERPLEXITY_API_KEY}
#spring.ai.openai.chat.options.model=llama-3.1-sonar-small-128k-online
#spring.ai.openai.chat.options.temperature=0.7

# Anthropic Claude (via OpenAI-compatible proxy)
#spring.ai.openai.base-url=https://api.anthropic.com/v1/openai
#spring.ai.openai.api-key=${ANTHROPIC_API_KEY}
#spring.ai.openai.chat.options.model=claude-3-sonnet-20240229
#spring.ai.openai.chat.options.temperature=0.7

# =============================================================================
# ADVANCED MODEL PARAMETERS
# =============================================================================

# Creative Writing Configuration
#spring.ai.openai.chat.options.temperature=0.9
#spring.ai.openai.chat.options.top-p=0.9
#spring.ai.openai.chat.options.frequency-penalty=0.5
#spring.ai.openai.chat.options.presence-penalty=0.5

# Analytical/Factual Configuration
#spring.ai.openai.chat.options.temperature=0.1
#spring.ai.openai.chat.options.top-p=0.1
#spring.ai.openai.chat.options.frequency-penalty=0.0
#spring.ai.openai.chat.options.presence-penalty=0.0

# Balanced Configuration (Default)
spring.ai.openai.chat.options.temperature=0.8
spring.ai.openai.chat.options.top-p=1.0
spring.ai.openai.chat.options.frequency-penalty=0.0
spring.ai.openai.chat.options.presence-penalty=0.0

# =============================================================================
# RETRY AND ERROR HANDLING CONFIGURATION
# =============================================================================

# Retry Configuration
spring.ai.retry.max-attempts=3
spring.ai.retry.backoff.initial-interval=2s
spring.ai.retry.backoff.multiplier=2
spring.ai.retry.backoff.max-interval=10s
spring.ai.retry.on-client-errors=false

# =============================================================================
# ENVIRONMENT-SPECIFIC CONFIGURATIONS
# =============================================================================

# Development Environment
#spring.profiles.active=dev
# Use local AI service for development
#spring.ai.openai.base-url=http://localhost:11434/v1
#spring.ai.openai.api-key=dev-key
#spring.ai.openai.chat.options.model=llama2

# Production Environment
#spring.profiles.active=prod
# Use official OpenAI for production
#spring.ai.openai.base-url=https://api.openai.com/v1
#spring.ai.openai.api-key=${OPENAI_API_KEY}
#spring.ai.openai.chat.options.model=gpt-4o

# Testing Environment
#spring.profiles.active=test
# Use mock service for testing
#spring.ai.openai.base-url=http://localhost:8080/mock-openai
#spring.ai.openai.api-key=test-key
#spring.ai.openai.chat.options.model=test-model

# =============================================================================
# SECURITY BEST PRACTICES
# =============================================================================

# Always use environment variables for sensitive data
# Example environment variables to set:
# export OPENAI_API_KEY="your-openai-api-key"
# export AZURE_OPENAI_API_KEY="your-azure-api-key"
# export GROQ_API_KEY="your-groq-api-key"
# export PERPLEXITY_API_KEY="your-perplexity-api-key"

# =============================================================================
# LOGGING CONFIGURATION FOR DEBUGGING
# =============================================================================

# Enable debug logging for Spring AI
#logging.level.org.springframework.ai=DEBUG
#logging.level.org.springframework.ai.openai=DEBUG
#logging.level.org.springframework.web.reactive.function.client=DEBUG

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# WebClient Configuration (if needed)
#spring.ai.openai.client.connect-timeout=10s
#spring.ai.openai.client.read-timeout=60s
#spring.ai.openai.client.write-timeout=60s

# Connection Pool Configuration
#spring.ai.openai.client.pool.max-connections=100
#spring.ai.openai.client.pool.max-idle-time=30s
